# These are the various CLIP models that are available

# The newer, larger Laion models

- model_id: "laion-clip-h"
  type: "clip"
  model: "laion/CLIP-ViT-H-14-laion2B-s32B-b79K"
  ignore_patterns: ["open_clip_*"]
- model_id: "laion-clip-g"
  type: "clip"
  model: "laion/CLIP-ViT-g-14-laion2B-s12B-b42K"
  ignore_patterns: ["open_clip_*"]
- model_id: "laion-clip-l"
  type: "clip"
  model: "laion/CLIP-ViT-L-14-laion2B-s32B-b82K"
  ignore_patterns: ["open_clip_*"]
- model_id: "laion-clip-b"
  type: "clip"
  model: "laion/CLIP-ViT-B-32-laion2B-s34B-b79K"
  ignore_patterns: ["open_clip_*"]

# The original OpenAI models

- model_id: "openai-clip-l"
  type: "clip"
  model: "openai/clip-vit-large-patch14"
- model_id: "openai-clip-b"
  type: "clip"
  model: "openai/clip-vit-base-patch32"

# This sets up a common clip that will be referred to be other models & engines
- model_id: "clip-common"
  type: "clip"
  model: "@laion-clip-h"
